---
keywords: fastai
description: How use W&B sweeps ro run the experiment in a notebook
title: Frictionless hyperparameter tuning with W&B and Jupyter Notebooks
toc: true 
badges: false
comments: true
author: Victor Rodriguez-Fernandez
categories: [wandb, jupyter]
image: images/chart-preview.png
nb_path: _notebooks/2021-09-26-sweeps.nbconvert.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-09-26-sweeps.nbconvert.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h1><p>I often find myself coding a machine learning experiment in a Jupyter Notebook, and at the same time, using <a href="https://www.wandb.com/">Weights &amp; Biases (wandb)</a> to visualize and track the results of the runs. When the experiment is finished, I always have questions such as: How will the performance be affected by the parameter a? What if I change the number of items of the dataset, or change the dataset completely?</p>
<p>Hyperpameter tuning with <a href="https://docs.wandb.com/sweeps">wandb sweeps</a> is a great tool to solve these questions. However, sweeping requires that you define a specific training program, as a separate python file. I find this to be redundant, specially when the code for training is already in the Jupyter Notebook. Furthermore, if I make some changes in the original notebook, I have to be sure that I change the sweep script too.</p>
<p>This post shows a trick to execute a Jupyter Notebook as the program of a wandb sweep. This provides a frictionless way of using your Jupyter Notebooks both for single runs and sweep functions. We won't use any separate configuration or script file, everything will be done between Jupyter and wandb. This post assumes that the reader has basic knowledge on both how Jupyter Notebooks and wandb sweeps work.</p>
<p>As use case we will perform a time series classification task with deep neural networks using the wonderful library <a href="https://github.com/timeseriesAI/tsai">tsai</a>. This is all the code needed to train a classifier in <code>tsai</code> for the dataset <a href="http://www.timeseriesclassification.com/description.php?Dataset=NATOPS">NATOPS</a>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tsai.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">dsid</span> <span class="o">=</span> <span class="s1">&#39;NATOPS&#39;</span> 
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">splits</span> <span class="o">=</span> <span class="n">get_UCR_data</span><span class="p">(</span><span class="n">dsid</span><span class="p">,</span> <span class="n">return_split</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">TSClassifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> 
                     <span class="n">batch_tfms</span><span class="o">=</span><span class="p">[</span><span class="n">TSStandardize</span><span class="p">()],</span> <span class="n">arch</span><span class="o">=</span><span class="n">InceptionTime</span><span class="p">,</span> 
                     <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">plot_metrics</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will do a hyperparameter search over the two arguments of the call to <code>fit_one_cycle</code>, that is, the number of epocs (<code>n_epochs</code>) and the maximum learning rate passed to the one-cycle schedule (<code>lr_max</code>).</p>
<p>In the next section, we'll see how to organize the notebook so that it is ready to be used as the program of a sweep. Then, we'll configure it to be run in a local server (e.g, an instance of JupyterLab). Finally, for Colab users, we'll see a workaround to make this work with a subtle difference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Refactoring-the-notebook-for-wandb-sweeps">Refactoring the notebook for wandb sweeps<a class="anchor-link" href="#Refactoring-the-notebook-for-wandb-sweeps"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As explained in the <a href="https://docs.wandb.ai/guides/sweeps/python-api">wandb documentation</a>: "two components work together in a sweep: a controller on the central sweep server, which picks out new hyperparameter combinations to try, and <strong>agents</strong>, running in any number of processes on any number of machines, which query the server for hyperparameters, use them to run model training, and then report the results back to the controller."</p>
<p>Each time the agent queries values of the hyperparameters for a new <em>trial</em>, those will be <em>injected</em> as part of the configuration of the wandb run that the training program must have. Once the program executes the call to <code>wandb.init</code> to begin the syncing, the object <code>wandb.config</code> will contain them, and any line of code that depends on that config will use the values pof that trial.</p>
<p>But, what happens if we had already defined a configuration object like the one below, before the call to <code>wandb.init</code> to play manually with different values?</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_epochs&#39;</span> <span class="p">:</span> <span class="mi">25</span><span class="p">,</span>
    <span class="s1">&#39;lr_max&#39;</span> <span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="s1">&#39;bs&#39;</span> <span class="p">:</span> <span class="mi">64</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">wandb</span>
<span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;disabled&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The good thing is that, nothing happens! Even if we have set values for <code>n_epochs</code> and <code>lr_max</code> before calling <code>wandb.init</code>, the sweep agent will override them with the values of the new trial. This is a <a href="https://docs.wandb.ai/guides/sweeps/faq">common question</a> explained in the wandb docs, and it is exactly what allows us to use the same exact notebook for both single runs and sweeps. Parameters that are not part of the sweep, such as <code>bs</code> in this example, can be part of the config object as well and of course they will be kept there by the sweep agent.</p>
<p>The last thing we have to do is, as in every sweep, replace our magic numbers (at least the ones that are part of the sweep) with the corresponding reference to the config variable:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tsai.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">dsid</span> <span class="o">=</span> <span class="s1">&#39;NATOPS&#39;</span> 
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">splits</span> <span class="o">=</span> <span class="n">get_UCR_data</span><span class="p">(</span><span class="n">dsid</span><span class="p">,</span> <span class="n">return_split</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">TSClassifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="p">[</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;bs&#39;</span><span class="p">],</span> <span class="mi">128</span><span class="p">],</span> 
                     <span class="n">batch_tfms</span><span class="o">=</span><span class="p">[</span><span class="n">TSStandardize</span><span class="p">()],</span> <span class="n">arch</span><span class="o">=</span><span class="n">InceptionTime</span><span class="p">,</span> 
                     <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">WandbCallback</span><span class="p">(</span><span class="n">log_preds</span><span class="o">=</span><span class="kc">False</span><span class="p">)])</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;n_epochs&#39;</span><span class="p">],</span> <span class="n">lr_max</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;lr_max&#39;</span><span class="p">])</span>
<span class="n">learn</span><span class="o">.</span><span class="n">plot_metrics</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So that's basically all you have to do to make your notebook ready for both single experiments &amp; sweepin: move your magic numbers that you want to sweep over to an initial config object, and pass that as config to <code>wandb.init</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Configuring-the-sweep">Configuring the sweep<a class="anchor-link" href="#Configuring-the-sweep"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are many ways to create the configuration of a new sweep for wandb:</p>
<ul>
<li>Use the graphical user interface</li>
<li>Create a separate yaml file</li>
<li>Define it somewhere in your notebook as a dictionary or a JSON object</li>
</ul>
<p>I like to use directly the graphical interface. In this way, I don't have to create a separate <code>yaml</code> file, and I don't have to touch my notebook, which makes everything cleaner. If you have never created a sweep using the wandb interface, there's a big button "Create new sweep" on the top-right corner of the sweeps tab</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://i.imgur.com/N5IyrTw.png" alt="" title="Create sweeps using the wandb interface"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You will see a nice YAML editor in which you have to define the parameters of the sweep, as well metric to optimize. You can also assign a name, a description, a method (we will use bayes here) and <a href="https://docs.wandb.ai/guides/sweeps/configuration">many more</a>. Below you can see how a sweep to search over the parameters <code>n_epoch</code> and <code>lr_max</code> with respect to the validation loss would look like, but wait until you press the "Initialize sweep" button...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://i.imgur.com/LKzR0uX.png" alt="" title="Sweep configuration with the default value for the program: train.py"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The trick comes with the <code>program</code> attribute. By default, wandb expects that you have defined a Python script called <code>train.py</code>, that contains your experiment synchronized with wandb. Our program is a Jupyter notebook though, so we will change this with the <strong>absolute path of our notebook in our Jupyter server</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="nt">program</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/home/victor/work/_notebooks/2021-09-26-sweeps.ipynb</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The question is: How are we going to execute the notebook? Obviously, if we run the sweep like this, wandb will try to execute the notebook as a Python script and the agent will crash. To solve this, we use the <a href="https://docs.wandb.ai/guides/sweeps/configuration#command"><code>command</code> key</a>. This configuration key tells the wandb agent the command structure for invoking and passing arguments to the training script. By default, it is defined as:</p>
<div class="highlight"><pre><span></span><span class="nt">command</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">${env}</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">${interpreter}</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">${program}</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">${args}</span>
</pre></div>
<p>where <code>${env}</code> is <code>/usr/bin/env</code> (in UNIX systems), <code>${interpreter}</code> expands to python, <code>${program}</code> is the file path of our training script (a notebook in our case), and <code>${args}</code> contain possible parameters of the classic form <code>--param1=value1</code>.</p>
<p>However, we can redefine the <code>command</code> as we wish. More specifically, to execute a notebook, we can make use of the <code>nbconvert</code> tool, part of the Jupyter ecosystem. The exact shell command that we have to type to execute the notebook is:</p>
<div class="highlight"><pre><span></span>jupyter nbconvert --to notebook --execute <span class="si">${</span><span class="nv">program</span><span class="si">}</span>
</pre></div>
<p>Since the sweep expects the command to be in <em>exec form</em> instead of <em>shell form</em>, we will add it to the sweep config as:</p>
<div class="highlight"><pre><span></span><span class="nt">command</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;jupyter&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;nbconvert&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;--to&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;notebook&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;--execute&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;${program}&quot;</span><span class="p p-Indicator">]</span>
</pre></div>
<p>And that's it! Now you can press the big blue "Initialize sweep button", and wandb will prompt you with a command to start an wandb agent that runs the sweep:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://i.imgur.com/pvsZ74J.png" alt="" title="To start the sweep, copy the agent command in a terminal"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Just copy that <code>wandb agent</code> into a terminal in your server and the sweep will start. You can create multiple instances of your agent in one or multiple machines. I use this a lot to use at once all the GPUs of my system in the sweep. As explained in <a href="https://wandb.ai/site/articles/multi-gpu-sweeps">this blog post</a>, it is just a matter of fixing the env variable <code>CUDA_VISIBLE_DEVICES</code> in each of the calls to the agent:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span>$ <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span> wandb agent vrodriguezf90/dummy_sweep/gs9p78yg
</pre></div>
<div class="highlight"><pre><span></span>$ <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span> wandb agent vrodriguezf90/dummy_sweep/gs9p78yg
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusions">Conclusions<a class="anchor-link" href="#Conclusions"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you are like me, and always procastinate doing hyperparameter tuning because of the extra boilerplate needed to make it work, this can be really useful when you work in Jupyter Notebooks. Since this post is in itself a Jupyter Notebook (Yes, you can write blog posts using Jupyter with <a href="https://github.com/fastai/fastpages">this awesome tool!</a>), I used it as a program for the sweep that was described in the previous section, and everything worked like a charm. You can visualize the sweep here.</p>
<p>Finally, it is worth to mention that the use of the tool <code>nbconvert</code> in each trial of the sweep creates a bit of overhead, which can be annoying, specially for small sweeps. There are multiple options to overcome this overhead, such as transforming the notebook into a script before configuring the sweep, or using faster tools to convert the notebook into a script such as the function <code>nb2py</code> from the <code>tsai</code> library.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Acknowledgments">Acknowledgments<a class="anchor-link" href="#Acknowledgments"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Thakn you to Ignacio Oguiza (El Gur√∫), for encouraging me to write this blog post, and for all the wonderful work and knowledge he puts into the tsai library.</p>

</div>
</div>
</div>
</div>
 

